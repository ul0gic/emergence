# =============================================================================
# Emergence — Environment Variables
# =============================================================================
# Copy this file to .env and fill in the values.
#   cp .env.example .env
#
# NEVER commit .env to version control.
# =============================================================================

# -----------------------------------------------------------------------------
# PostgreSQL (Event Store / Cold State)
# -----------------------------------------------------------------------------
POSTGRES_DB=emergence
POSTGRES_USER=emergence
POSTGRES_PASSWORD=changeme
POSTGRES_PORT=5432

# Full connection string used by the World Engine and sqlx
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost:${POSTGRES_PORT}/${POSTGRES_DB}

# -----------------------------------------------------------------------------
# Dragonfly (Hot State — Redis-compatible)
# -----------------------------------------------------------------------------
DRAGONFLY_PORT=6379
DRAGONFLY_URL=redis://localhost:${DRAGONFLY_PORT}

# -----------------------------------------------------------------------------
# NATS (Event Bus / Messaging)
# -----------------------------------------------------------------------------
NATS_PORT=4222
NATS_MONITOR_PORT=8222
NATS_URL=nats://localhost:${NATS_PORT}

# -----------------------------------------------------------------------------
# LLM Backend — Default (routine agent decisions)
# -----------------------------------------------------------------------------
# Primary backend: OpenRouter provides a single API gateway for all models.
# DeepSeek V3 is extremely cost-effective for routine decisions (gathering,
# moving, resting) at $0.30/$0.88 per million tokens (input/output).
LLM_DEFAULT_BACKEND=openrouter
LLM_DEFAULT_API_URL=https://openrouter.ai/api/v1
LLM_DEFAULT_API_KEY=
LLM_DEFAULT_MODEL=deepseek/deepseek-chat-v3-0324

# -----------------------------------------------------------------------------
# LLM Backend — Escalation (complex decisions: discoveries, conflicts)
# -----------------------------------------------------------------------------
# Escalation backend: Also routed through OpenRouter (single API key for all
# models). Claude Sonnet 4.5 handles high-stakes decisions where nuance matters
# (social conflicts, discoveries, governance, diplomacy). Only invoked when
# tick complexity scoring exceeds the routine threshold.
LLM_ESCALATION_BACKEND=openrouter
LLM_ESCALATION_API_URL=https://openrouter.ai/api/v1
LLM_ESCALATION_API_KEY=
LLM_ESCALATION_MODEL=anthropic/claude-sonnet-4-5-20250929

# -----------------------------------------------------------------------------
# OpenRouter-specific headers
# -----------------------------------------------------------------------------
# OpenRouter requires HTTP-Referer and X-Title headers for ranking and
# attribution. These are sent on every request when the backend is openrouter.
OPENROUTER_HTTP_REFERER=http://localhost:8080
OPENROUTER_APP_TITLE=Emergence

# -----------------------------------------------------------------------------
# Cost tracking (price per million tokens, used for cost estimation)
# -----------------------------------------------------------------------------
# Rates from OpenRouter pricing. Used by the CostTracker to estimate spend.
# Set to 0 or leave empty to disable cost estimation for a backend.
LLM_DEFAULT_COST_PER_M_INPUT=0.30
LLM_DEFAULT_COST_PER_M_OUTPUT=0.88
LLM_ESCALATION_COST_PER_M_INPUT=3.00
LLM_ESCALATION_COST_PER_M_OUTPUT=15.00

# -----------------------------------------------------------------------------
# Alternative: Direct OpenAI backend (uncomment to use instead of OpenRouter)
# -----------------------------------------------------------------------------
# LLM_DEFAULT_BACKEND=openai
# LLM_DEFAULT_API_URL=https://api.openai.com/v1
# LLM_DEFAULT_API_KEY=
# LLM_DEFAULT_MODEL=gpt-5-nano-2025-08-07
# LLM_DEFAULT_COST_PER_M_INPUT=0.10
# LLM_DEFAULT_COST_PER_M_OUTPUT=0.40

# -----------------------------------------------------------------------------
# Alternative: Direct Anthropic backend (uncomment to use instead of OpenRouter)
# -----------------------------------------------------------------------------
# LLM_ESCALATION_BACKEND=anthropic
# LLM_ESCALATION_API_URL=https://api.anthropic.com/v1
# LLM_ESCALATION_API_KEY=
# LLM_ESCALATION_MODEL=claude-haiku-4-5-20251001
# LLM_ESCALATION_COST_PER_M_INPUT=1.00
# LLM_ESCALATION_COST_PER_M_OUTPUT=5.00

# -----------------------------------------------------------------------------
# Operator Controls
# -----------------------------------------------------------------------------
# Bearer token for authenticating operator REST API requests (pause, resume,
# speed control, event injection). Leave empty to disable auth (dev only).
OPERATOR_API_TOKEN=

# -----------------------------------------------------------------------------
# Observer Dashboard
# -----------------------------------------------------------------------------
OBSERVER_PORT=8080

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
RUST_LOG=info
